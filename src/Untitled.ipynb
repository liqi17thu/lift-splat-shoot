{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supposed-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_scatter\n",
    "from torch_scatter import scatter_sum\n",
    "from data import compile_data\n",
    "from matplotlib import pyplot as plt\n",
    "from pointpillar import PointPillar\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naval-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.tensor([[[2, 1], [0, 1], [1, 1], [1, 4], [2, 3]], [[0, 0], [0, 2], [1, 2], [1, 3], [2, 4]]]) # (B,5, 2)     (B, N, C)\n",
    "index = torch.tensor([[4, 5, 4, 2, 3], [0, 0, 2, 2, 1]]) # (B, 2, 5)  #(B, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "refined-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0],\n",
       "         [1, 4],\n",
       "         [2, 3],\n",
       "         [3, 2],\n",
       "         [0, 1],\n",
       "         [0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 2],\n",
       "         [2, 4],\n",
       "         [2, 5],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_scatter.scatter_sum(src, index, dim=1, dim_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verbal-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'mini'\n",
    "dataroot='/mnt/datasets/nuScenes'\n",
    "\n",
    "xbound=[-30.0, 30.0, 0.15]\n",
    "ybound=[-15.0, 15.0, 0.15]\n",
    "zbound=[-10.0, 10.0, 20.0]\n",
    "dbound=[4.0, 45.0, 1.0]\n",
    "\n",
    "H=900\n",
    "W=1600\n",
    "resize_lim=(0.193, 0.225)\n",
    "final_dim=(128, 352)\n",
    "bot_pct_lim=(0.0, 0.22)\n",
    "rot_lim=(-5.4, 5.4)\n",
    "rand_flip=True\n",
    "ncams=5\n",
    "max_grad_norm=5.0\n",
    "\n",
    "bsz=4\n",
    "nworkers=10\n",
    "\n",
    "grid_conf = {\n",
    "    'xbound': xbound,\n",
    "    'ybound': ybound,\n",
    "    'zbound': zbound,\n",
    "    'dbound': dbound,\n",
    "}\n",
    "data_aug_conf = {\n",
    "    'resize_lim': resize_lim,\n",
    "    'final_dim': final_dim,\n",
    "    'rot_lim': rot_lim,\n",
    "    'H': H, 'W': W,\n",
    "    'rand_flip': rand_flip,\n",
    "    'bot_pct_lim': bot_pct_lim,\n",
    "    'cams': ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT',\n",
    "             'CAM_BACK_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT'],\n",
    "    'Ncams': ncams,\n",
    "    'preprocess': False,\n",
    "    'line_width': 5,\n",
    "\n",
    "}\n",
    "parser_name = 'segmentationdata'\n",
    "\n",
    "[trainloader, valloader], [train_sampler, val_sampler] = compile_data(version, dataroot, data_aug_conf=data_aug_conf,\n",
    "                                                              grid_conf=grid_conf, bsz=bsz, nworkers=nworkers,\n",
    "                                                              parser_name=parser_name, distributed=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neither-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in trainloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handled-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_xyz, points_mask = d[0], d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automatic-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = PointPillar(3, xbound, ybound, zbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afraid-vienna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 400, 200])\n",
      "torch.Size([4, 256, 400, 200])\n"
     ]
    }
   ],
   "source": [
    "points_feature = pp(points_xyz, points_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "healthy-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 400, 200])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raval_index(coords, dims):\n",
    "    dims = torch.cat((dims, torch.ones(1, device=dims.device)), dim=0)[1:]\n",
    "    dims = torch.flip(dims, dims=[0])\n",
    "    dims = torch.cumprod(dims, dim=0) / dims[0]\n",
    "    multiplier = torch.flip(dims, dims=[0])\n",
    "    indices = torch.sum(coords * multiplier, dim=1)\n",
    "    return indices\n",
    "\n",
    "def points_to_voxels(\n",
    "  points_xyz,\n",
    "  points_mask,\n",
    "  grid_range_x,\n",
    "  grid_range_y,\n",
    "  grid_range_z\n",
    "):\n",
    "    batch_size, num_points, _ = points_xyz.shape\n",
    "    voxel_size_x = grid_range_x[2]\n",
    "    voxel_size_y = grid_range_y[2]\n",
    "    voxel_size_z = grid_range_z[2]\n",
    "    grid_size = np.asarray([\n",
    "        (grid_range_x[1]-grid_range_x[0]) / voxel_size_x,\n",
    "        (grid_range_y[1]-grid_range_y[0]) / voxel_size_y,\n",
    "        (grid_range_z[1]-grid_range_z[0]) / voxel_size_z\n",
    "    ]).astype('int32')\n",
    "    voxel_size = np.asarray([voxel_size_x, voxel_size_y, voxel_size_z])\n",
    "    voxel_size = torch.Tensor(voxel_size).to(points_xyz.device)\n",
    "    num_voxels = grid_size[0] * grid_size[1] * grid_size[2]\n",
    "    grid_offset = torch.Tensor([grid_range_x[0], grid_range_y[0], grid_range_z[0]]).to(points_xyz.device)\n",
    "    shifted_points_xyz = points_xyz - grid_offset\n",
    "    voxel_xyz = shifted_points_xyz / voxel_size\n",
    "    voxel_coords = voxel_xyz.int()\n",
    "    grid_size = torch.from_numpy(grid_size).to(points_xyz.device)\n",
    "    grid_size = grid_size.int()\n",
    "    zeros = torch.zeros_like(grid_size)\n",
    "    voxel_paddings = ((points_mask < 1.0) | \n",
    "                      torch.any((voxel_coords >= grid_size) | \n",
    "                                (voxel_coords < zeros), dim=-1))\n",
    "    voxel_indices = raval_index(\n",
    "      torch.reshape(voxel_coords, [batch_size * num_points, 3]), grid_size)\n",
    "    voxel_indices = torch.reshape(voxel_indices, [batch_size, num_points])\n",
    "    voxel_indices = torch.where(voxel_paddings,\n",
    "                                torch.zeros_like(voxel_indices),\n",
    "                                voxel_indices)\n",
    "    voxel_centers = ((0.5 + voxel_coords.float()) * voxel_size + grid_offset)\n",
    "    voxel_coords = torch.where(torch.unsqueeze(voxel_paddings, dim=-1),\n",
    "                               torch.zeros_like(voxel_coords),\n",
    "                               voxel_coords)\n",
    "    voxel_xyz = torch.where(torch.unsqueeze(voxel_paddings, dim=-1),\n",
    "                            torch.zeros_like(voxel_xyz),\n",
    "                            voxel_xyz)\n",
    "    voxel_paddings = voxel_paddings.float()\n",
    "    \n",
    "    voxel_indices = voxel_indices.long()\n",
    "    points_per_voxel = torch_scatter.scatter_sum(\n",
    "        torch.ones((batch_size, num_points), dtype=voxel_coords.dtype, device=voxel_coords.device) * (1-voxel_paddings),\n",
    "        voxel_indices, \n",
    "        dim=1,\n",
    "        dim_size=num_voxels\n",
    "    )\n",
    "    \n",
    "    voxel_point_count = torch.gather(points_per_voxel,\n",
    "                                     dim=1,\n",
    "                                     index=voxel_indices)\n",
    "    \n",
    "    \n",
    "    voxel_centroids = torch_scatter.scatter_mean(\n",
    "        points_xyz,\n",
    "        voxel_indices, \n",
    "        dim=1,\n",
    "        dim_size=num_voxels)\n",
    "    point_centroids = torch.gather(voxel_centroids, dim=1, index=torch.unsqueeze(voxel_indices, dim=-1).repeat(1, 1, 3))\n",
    "    local_points_xyz = points_xyz - point_centroids\n",
    "    \n",
    "    \n",
    "    result = {\n",
    "        'local_points_xyz': local_points_xyz,\n",
    "        'shifted_points_xyz': shifted_points_xyz,\n",
    "        'point_centroids': point_centroids,\n",
    "        'points_xyz': points_xyz,\n",
    "        'grid_offset': grid_offset,\n",
    "        'voxel_coords': voxel_coords,\n",
    "        'voxel_centers': voxel_centers,\n",
    "        'voxel_indices': voxel_indices,\n",
    "        'voxel_paddings': voxel_paddings,\n",
    "        'voxel_mask': 1 - voxel_paddings,\n",
    "        'num_voxels': num_voxels,\n",
    "        'grid_size': grid_size,\n",
    "        'voxel_xyz': voxel_xyz,\n",
    "        'voxel_size': voxel_size,\n",
    "        'voxel_point_count': voxel_point_count,\n",
    "        'points_per_voxel': points_per_voxel,\n",
    "        'voxel_centroids': voxel_centroids,\n",
    "    }\n",
    "    \n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = points_to_voxels(points_xyz[:, :, :3], points_mask, xbound, ybound, zbound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['voxel_centroids'].view(4, result['grid_size'][0],  result['grid_size'][1], 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result['points_per_voxel'].cpu()[0].numpy().reshape(400, 200) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['points_per_voxel'][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_mask[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['voxel_xyz'][0, 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['voxel_indices'][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['grid_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_mask[0][0: 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray((7, 3, 2)) - a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_trim_to_np(x, shape, pad_val=0):\n",
    "    shape = np.asarray(shape)\n",
    "    pad = shape - np.minimum(np.shape(x), shape)\n",
    "    zeros = np.zeros_like(pad)\n",
    "    x = np.pad(x, np.stack([zeros, pad], axis=1), constant_values=pad_val)\n",
    "    return x[:shape[0], :shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_or_trim_to_np(a, [7, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raval_index(coords, dims):\n",
    "    dims = dims[::-1]\n",
    "    dims = torch.cumprod(dims, dim=0) / dims[0]\n",
    "    dims = dims[::-1]\n",
    "    indices = torch.sum(coords * multiplier, dim=1)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-receipt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
